## Начальные сведения 
* Виртуалке были даны 2 ядра (будем надеяться, что не помрет)
* Конфигурация кластера: 3 ноды
* Реплицирование по умолчанию (2/3)

## PUT 30000 30s 4 threads 64 con

Сначала попробуем найти новую точку разладки. Сравнивая входные данные с прошлого этапа, что почему-то больше 1 потока
и 1 соединения не проходило, количество запросов упало до 3000-5000. В этот раз мало что изменилось. По входных данным
4 потока и 64 соединения результаты в [put-profile-4th-64con-30000.txt](put-profile-4th-64con-30000.txt). Очень мало
запросов в приципе успевают обработаться и большинство ловят TimeOut.

```
 50.000%   20.07s
 75.000%   24.92s
 90.000%   27.93s
 99.000%   29.74s
 99.900%   29.77s
 99.990%   29.77s
 99.999%   29.77s
100.000%   29.77s
```

## PUT 3000 30s 1 thread 1 con

Тогда вернемся к работающим входным данным прошлого этапа. Результаты эксперимента в сравнении с прошлым этапом при
1 поток, 1 соединение, 3000 запросов приведены ниже.

```
            было        стало
 50.000%   19.32s       21.04s
 75.000%   23.40s       24.48s
 90.000%   26.05s       25.85s
 99.000%   27.61s       27.34s
 99.900%   27.69s       27.46s
 99.990%   27.71s       27.48s
 99.999%   27.71s       27.48s
100.000%   27.71s       27.48s 
```

На 50-ом перцентиле время выросло, на других в прицнипе не изменилось. Также можно отметить, что по результатам
подобного эксперимента на прошлом этапе и на этом меньше половины запросов успевают обработаться.

При времени 30 секунд и 3000 запросов результат: 7576 requests in 30.00s, 495.70KB read. Я все же предполагаю, что это
из-за предоставленных виртуалке ресурсов.

Также стоит отметить, что при добавлении пересылки по сети из-за наличия реплицирования, время обработки должно
было увеличиться. Однако об этом сложно судить при таких результатах эксперимента.

## CPU

[put-profile-1th-cpu.html](put-profile-1th-cpu.html)

В сравнении с прошлым этапом ситуация особым образом не поменялась. Все также тратиться время на отправку ответа
клиенту и ожидание ответа от других нод. Еще также сама обработка логики. Больше всего времени остается за операцией
Unsafe.park (3.34%), которая, как я понимаю, и занимается блокировкой и ожиданием потока.

Так как в этом этапе происходила работа с хэдерами запросом (0.30%), теперь они также отражаются на фрейм-графах.

В другой нагрузке:
- ThreadPoolExecutor.runWorker: с 24.07% до 46.93% увеличилось. Работа с запросами происходит в основном в ворекерах,
соответсвенно и увеличилась нагрузка.
- HttpClientImpl$SelectorManager.run: с 11.14% до 20.10% увеличилось. Предположение: из-за работы с http-запросами.
- ThreadPoolExecutor.getTask: с 9.30% до 16.70% увеличилось

## ALLOC

[put-profile-1th-alloc.html](put-profile-1th-alloc.html)



## LOCK

[put-profile-1th-lock.html](put-profile-1th-lock.html)

## GET 5000 30s 1 thread 1 con

Аналогично как и с запросами PUT было решение попробовать при тех же входных данных, как в прошлом этапе, то есть 
1 соединение, 1 поток, 5000 запросов. Результаты перцентилей приведены ниже.

```
            было        стало
 50.000%   19.55s       19.96s
 75.000%   23.79s       24.76s
 90.000%   25.85s       27.25s
 99.000%   27.34s       28.48s
 99.900%   27.46s       28.56s
 99.990%   27.46s       28.57s
 99.999%   27.46s       28.57s
100.000%   27.46s       28.57s
```

Видно, что время вырасло на секунды. Но предполагая также как и с PUT-запросами сложно судить, произошло это из-за
наличия реплицирования или из-за ресурсов виртуалки.

## CPU

[get-profile-1th-cpu.html](get-profile-1th-cpu.html)

## ALLOC

[get-profile-1th-alloc.html](get-profile-1th-alloc.html)

## LOCK

[get-profile-1th-lock.html](get-profile-1th-lock.html)

