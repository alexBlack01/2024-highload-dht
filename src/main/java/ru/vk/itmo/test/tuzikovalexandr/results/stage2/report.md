## PUT 500 10s 8 threads

Сначала попробуем подать нагрузку, используя 1 поток и 1 соедниене.

```
 50.000%    2.49ms
 75.000%    3.52ms
 90.000%   16.51ms
 99.000%  147.07ms
 99.900%  191.87ms
 99.990%  194.94ms
 99.999%  194.94ms
100.000%  194.94ms
```

Далее увеличим количество потоков до 8 и количествое соединений до 64.
Результат оказался следующий: 

```
 50.000%    2.54ms
 75.000%    3.60ms
 90.000%   13.36ms
 99.000%   51.97ms
 99.900%   82.50ms
 99.990%   87.10ms
 99.999%   87.10ms
100.000%   87.10ms
```

По результатам можно отметить, что на 90-ом перцентиле время уменьшается, 
а на 99-ом и далее даже в 2 раза.

Стоит отметить, что при проведении экспериментов на второй стадии, у виртуальной машины было
изменено количество доступных процессоров с 2 до 4 и объем оперативной памяти с 4 ГБ до 8 ГБ.
Однако, ни к каким улучшениям это не привело.

## PUT 25000 30s 8 threads

Теперь проведем эксперимент на 25000 запросов, так как это было некоторой точкой, 
когда сервер начинал плохо работать.

```
 50.000%   17.17s 
 75.000%   21.45s 
 90.000%   24.82s 
 99.000%   27.72s 
 99.900%   27.84s 
 99.990%   27.87s 
 99.999%   27.92s 
100.000%   27.92s 
```

```
 50.000%   10.65ms
 75.000%  107.65ms
 90.000%  308.99ms
 99.000%  525.82ms
 99.900%  586.75ms
 99.990%  662.53ms
 99.999%  691.20ms
100.000%  695.81ms
```

Аналогично как и с предыдущим экспериментом можно ответить, что прирост в скорости значительный.

## Анализ Flame Graph (CPU PUT запросов)

Далее проведем эксперимент профилирования с несколькими соединениями и потоками, чтобы посмотреть, 
как теперь распределеяется трата ресурсов. Как входые параметры было подано 25000 запросов, 8 потоков и
64 соединения. На диаграмме put-profile-8c-cpu.html предствлены результаты эксперимента.

Можно отметить, что теперь селекторы не тратят свои ресурсы на выполнение логики запроса.
Так мы высвободили ресурсы для его базовой задачи - обработки следующих запросов (около 20%). 
Также это чтение и отправка входящих запросов и поллинг. Еще 1% тратится на работу с блокировкой у очереди.

Обработкой логики запросов и чтением их из очереди занимаются сами воркеры (> 70%). Тут также можно отметить,
что чуть более 15% уходит на работу с очередью. 

В остальном, как это и было раньше, но у селекторов, теперь воркеры занимаются работой с бд и записью ответов в сокет.

Как итог из общей тенденции: происходит выигрыш во времени работы селектора, обработки запроса им же, но теперь
добавляется нагрузка на поллинг.

## Анализ Flame Graph (PUT запросов) работа селекторов и потоков

Был проведен эксперимент, где на вход подавался 1 поток и 8 соединений. Напомню, что виртуальной машине было
выделено 4 ядра.

Результаты на диаграмме put-profile-1th-8c.html.

Очень интересное замечение, что количество селекторов в результате получилось всего 3.
Есть предположение, что это ограничение ОС или гипервизора. В случае виртуальных машин, гипервизоры, 
такие как VMware ESXi, Microsoft Hyper-V, или Oracle VirtualBox, могут вводить определённые 
ограничения на использование аппаратных ресурсов виртуализированными системами, что 
также может сказаться на количестве эффективно используемых потоков.

## Flame Graph (ALLOC PUT запросов)

Результаты на диаграмме put-profile-8th-alloc.html.

Все как и аналогично выше, так как теперь логику обработки запросов взяли на себя воркеры, нагрузка на селекторы
сильно уменьшилась. Но добавились незначительные расходы ресурсов на создание воркеров и их работу.

## GET 25000 30s 8 threads

При анализе улучшений GET-запросов сразу дадим высокую нагрузку. И, как аналогично, сначала будет 1 поток, 1 соединение,
потом 8 потоков, 64 соединения.

```
 50.000%   18.06s 
 75.000%   22.99s 
 90.000%   25.46s 
 99.000%   27.46s 
 99.900%   27.66s 
 99.990%   27.67s 
 99.999%   27.69s 
100.000%   27.69s 
```

```
 50.000%  312.58ms
 75.000%  954.88ms
 90.000%    1.43s 
 99.000%    1.85s 
 99.900%    1.96s 
 99.990%    2.01s 
 99.999%    2.03s 
100.000%    2.03s 
```

Как можно заметить результаты улучшились в 10 раз. И запросов при наличии большего числа потоков и соединений
обрабатывается также больше. Как и с PUT-запросами причины улучшения - разгрузка селекторов.

## Анализ Flame Graph (CPU GET запросов)

Далее проведем эксперимент профилирования с несколькими соединениями и потоками, чтобы посмотреть,
как теперь распределеяется трата ресурсов уже для GET-запросов. Как входые параметры было подано 25000 запросов, 
8 потоков и 64 соединения. На диаграмме get-profile-8c-cpu.html предствлены результаты эксперимента.

Аналогично, как и с PUT-запросами ситуация с воркерами.

## Новая точка разладки

Так как изначально максимальный размер очереди выставлен 1000, попробуем и количество соединений увеличить 
до такого числа.